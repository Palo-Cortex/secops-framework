name: SOC Packs Release v2

on:
  push:
    branches:
      - staging
      - main

permissions:
  contents: write

env:
  PACKS_DIR: Packs
  DEMISTO_SDK_VERSION: "1.38.14"
  DEMISTO_SDK_IGNORE_CONTENT_WARNING: "1"

jobs:
  ###########################################################################
  # JOB 1 — Detect packs to build + update catalog
  ###########################################################################
  detect-packs:
    runs-on: ubuntu-latest

    outputs:
      packs_json: ${{ steps.detect.outputs.packs_json }}
      environment: ${{ steps.envinfo.outputs.environment }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Determine environment (main vs staging)
        id: envinfo
        run: |
          if [ "${GITHUB_REF##*/}" = "main" ]; then
            echo "environment=main" >> "$GITHUB_OUTPUT"
          else
            echo "environment=staging" >> "$GITHUB_OUTPUT"
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Detect version-bumped packs & update catalog
        id: detect
        env:
          ENVIRONMENT: ${{ steps.envinfo.outputs.environment }}
        run: |
          import json, os, subprocess, glob, datetime, pathlib

          env = os.environ["ENVIRONMENT"]
          packs_dir = os.environ.get("PACKS_DIR", "Packs")
          # Choose catalog file based on branch
          catalog_file = "catalog-main.json" if env == "main" else "catalog-staging.json"

          # ------------------------------------------------------------------
          # 1) Find pack_metadata.json files whose currentVersion changed
          # ------------------------------------------------------------------
          # Default base commit: HEAD^ (previous commit)
          try:
            base_commit = subprocess.check_output(
              ["git", "rev-parse", "HEAD^"],
              text=True
            ).strip()
          except subprocess.CalledProcessError:
            # First commit or shallow checkout – treat all packs as changed
            base_commit = None

          changed_packs = set()

          if base_commit:
            diff_files = subprocess.check_output(
              ["git", "diff", "--name-only", f"{base_commit}..HEAD"],
              text=True
            ).splitlines()
          else:
            diff_files = []

          for path in diff_files:
            if not path.startswith(f"{packs_dir}/") or not path.endswith("pack_metadata.json"):
              continue

            # Extract pack_id from path like Packs/pack-id/pack_metadata.json
            parts = path.split("/")
            if len(parts) < 3:
              continue
            pack_id = parts[1]

            # Load new metadata
            with open(path, "r", encoding="utf-8") as f:
              new_meta = json.load(f)
            new_ver = new_meta.get("currentVersion")

            # Load old metadata (if existed)
            old_ver = None
            try:
              old_raw = subprocess.check_output(
                ["git", "show", f"{base_commit}:{path}"],
                text=True
              )
              old_meta = json.loads(old_raw)
              old_ver = old_meta.get("currentVersion")
            except subprocess.CalledProcessError:
              # New file / new pack – treat as version changed
              old_ver = None

            if old_ver != new_ver:
              changed_packs.add(pack_id)

          # If base_commit is None (first run / shallow), treat ALL packs as changed
          if base_commit is None:
            for meta_path in glob.glob(os.path.join(packs_dir, "*/pack_metadata.json")):
              pack_id = pathlib.Path(meta_path).parts[1]
              changed_packs.add(pack_id)

          # ------------------------------------------------------------------
          # 2) Load existing catalog to preserve manual "visible" + "order"
          # ------------------------------------------------------------------
          existing_visible = {}
          existing_order = {}
          try:
            with open(catalog_file, "r", encoding="utf-8") as f:
              existing = json.load(f)
              for p in existing.get("packs", []):
                pid = p.get("id")
                if not pid:
                  continue
                existing_visible[pid] = p.get("visible", True)
                if "order" in p:
                  existing_order[pid] = p["order"]
          except FileNotFoundError:
            pass

          # ------------------------------------------------------------------
          # 3) Rebuild catalog from ALL packs, but keep visible/order when present
          # ------------------------------------------------------------------
          repo = os.environ.get("GITHUB_REPOSITORY", "")
          ref_name = os.environ.get("GITHUB_REF_NAME", "")
          raw_base = f"https://raw.githubusercontent.com/{repo}/{ref_name}"

          catalog_packs = []
          for meta_path in sorted(glob.glob(os.path.join(packs_dir, "*/pack_metadata.json"))):
            parts = pathlib.Path(meta_path).parts
            pack_id = parts[1]

            with open(meta_path, "r", encoding="utf-8") as f:
              meta = json.load(f)

            display_name = meta.get("name", pack_id)
            description = meta.get("description", "")
            version = meta.get("currentVersion", "")
            # dependencies can be dict {"PackName": {...}}, take the keys
            deps_raw = meta.get("dependencies", {})
            if isinstance(deps_raw, dict):
              dependencies = list(deps_raw.keys())
            else:
              dependencies = []

            # Very simple category heuristic; you can refine later
            category = meta.get("category") or "Uncategorized"

            visible = existing_visible.get(pack_id, True)      # default visible
            order = existing_order.get(pack_id, 100)           # default sort

            # Assuming prepare-content drops <pack_id>.zip inside the pack folder
            download_url = f"{raw_base}/{packs_dir}/{pack_id}/{pack_id}.zip"

            catalog_packs.append({
              "id": pack_id,
              "display_name": display_name,
              "category": category,
              "description": description,
              "version": version,
              "download_url": download_url,
              "dependencies": dependencies,
              "visible": visible,
              "order": order
            })

          catalog = {
            "environment": env,
            "generated_at": datetime.datetime.utcnow().isoformat() + "Z",
            "packs": catalog_packs,
          }

          with open(catalog_file, "w", encoding="utf-8") as f:
            json.dump(catalog, f, indent=2)
            f.write("\n")

          # ------------------------------------------------------------------
          # 4) Expose changed packs as job output
          # ------------------------------------------------------------------
          packs_list = sorted(changed_packs)
          print("Version-bumped packs:", packs_list)

          github_output = os.environ["GITHUB_OUTPUT"]
          with open(github_output, "a", encoding="utf-8") as f:
            f.write(f"packs_json={json.dumps(packs_list)}\n")

        shell: python

      - name: Show detected packs
        run: |
          echo "Environment: ${{ steps.envinfo.outputs.environment }}"
          echo "Packs with version bump: ${{ steps.detect.outputs.packs_json }}"

  ###########################################################################
  # JOB 2 — Package only the packs whose versions changed
  ###########################################################################
  release-packs:
    needs: detect-packs
    runs-on: ubuntu-latest
    if: ${{ needs.detect-packs.outputs.packs_json != '[]' && needs.detect-packs.outputs.packs_json != '' }}

    strategy:
      fail-fast: false
      matrix:
        pack_id: ${{ fromJson(needs.detect-packs.outputs.packs_json) }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install demisto-sdk
        run: |
          python -m pip install --upgrade pip
          pip install "demisto-sdk==${{ env.DEMISTO_SDK_VERSION }}"

      - name: Package pack with prepare-content
        env:
          PACK_ID: ${{ matrix.pack_id }}
          PACKS_DIR: ${{ env.PACKS_DIR }}
        run: |
          echo "Packaging pack: ${PACK_ID}"
          ls -R

          # Input pack folder: Packs/<pack_id>
          INPUT_DIR="${PACKS_DIR}/${PACK_ID}"
          OUTPUT_DIR="${PACKS_DIR}/${PACK_ID}"

          if [ ! -d "$INPUT_DIR" ]; then
            echo "ERROR: Pack directory not found: $INPUT_DIR"
            exit 1
          fi

          demisto-sdk prepare-content \
            -i "$INPUT_DIR" \
            -o "$OUTPUT_DIR" \
            -mp XSIAM \
            -f

          echo "Contents of output dir:"
          ls -l "$OUTPUT_DIR"

      # Optional: commit catalog + zips back to the repo (only on main/staging)
      - name: Commit catalog & zips (if any changes)
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/staging'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git status

          # Stage only catalog + zip files
          git add catalog-main.json catalog-staging.json || true
          git add Packs/*/*.zip || true

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "chore: update pack zips & catalog [skip ci]"
          git push
